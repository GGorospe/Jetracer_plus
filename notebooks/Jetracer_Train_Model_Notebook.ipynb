{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee8861fa-15e4-44b3-b60b-4e381ed34b09",
      "metadata": {
        "id": "ee8861fa-15e4-44b3-b60b-4e381ed34b09"
      },
      "source": [
        "# Jetracer Convolutional Neural Network Model Training Notebook\n",
        "Author: George Gorospe (updated 1/12/2024)\n",
        "\n",
        "\n",
        "\n",
        "About: In this notebook we'll use the the data we previously collected to train a Convolutional Neural Network (CNN). This network will take as input an image from the racer's camera, and output the inferred driving directions in the form of a steering angle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e13514-020a-42aa-bfb3-ff77a3f51c9a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-03T06:15:55.870862Z",
          "iopub.status.busy": "2024-01-03T06:15:55.869892Z",
          "iopub.status.idle": "2024-01-03T06:16:02.841650Z",
          "shell.execute_reply": "2024-01-03T06:16:02.839083Z",
          "shell.execute_reply.started": "2024-01-03T06:15:55.870785Z"
        },
        "id": "75e13514-020a-42aa-bfb3-ff77a3f51c9a"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from xy_dataset import XYDataset\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2, glob, os, fnmatch, time\n",
        "from datetime import datetime\n",
        "from matplotlib.patches import Circle\n",
        "\n",
        "\n",
        "#Loading a GPU if avaliable and otherwise a CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed46c925-1997-42e1-bced-49ad9d76faf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-03T06:16:02.858584Z",
          "iopub.status.busy": "2024-01-03T06:16:02.856220Z",
          "iopub.status.idle": "2024-01-03T06:16:02.974336Z",
          "shell.execute_reply": "2024-01-03T06:16:02.972529Z",
          "shell.execute_reply.started": "2024-01-03T06:16:02.858529Z"
        },
        "id": "ed46c925-1997-42e1-bced-49ad9d76faf9",
        "outputId": "ffbeb9ab-dcae-408a-d584-a3a872fff110"
      },
      "outputs": [],
      "source": [
        "# Locating Dataset for Training\n",
        "\n",
        "################# [REQUIRED ACTION] Select the Directory with your Dataset ##########################\n",
        "DATASET_DIR = \"/Datasets\"\n",
        "dataset_folder_name = DATASET_DIR.split(\"/\")[-2]\n",
        "\n",
        "# Information about the dataset, number of data points and a listing of the data points.\n",
        "num_files =  len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
        "file_list = fnmatch.filter(os.listdir(DATASET_DIR), '*.jpg')\n",
        "if num_files > 0:\n",
        "  print(\"Dataset found!\")\n",
        "  print(\"Number of files found in datadset: \" + str(num_files))\n",
        "elif num_files == 0:\n",
        "  print(\"No data in selected directory, choose again?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0021bd10-b891-4c86-ab9f-8527251450ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-01-03T06:16:02.979578Z",
          "iopub.status.busy": "2024-01-03T06:16:02.977177Z",
          "iopub.status.idle": "2024-01-03T06:16:03.140504Z",
          "shell.execute_reply": "2024-01-03T06:16:03.139344Z",
          "shell.execute_reply.started": "2024-01-03T06:16:02.979526Z"
        },
        "id": "0021bd10-b891-4c86-ab9f-8527251450ab",
        "outputId": "b92578b0-e7af-472a-e166-e690c4784dfe"
      },
      "outputs": [],
      "source": [
        "# Creating our dataset object. This object parses the file names to get the labels for each datapoint\n",
        "\n",
        "TRANSFORMS = transforms.Compose([\n",
        "    #transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
        "    #transforms.ColorJitter(brightness=.5, hue=.3),\n",
        "    #transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "Sample_Dataset = XYDataset(DATASET_DIR,TRANSFORMS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ATwFEyCbKMcp",
      "metadata": {
        "id": "ATwFEyCbKMcp"
      },
      "outputs": [],
      "source": [
        "# Using sklearn to split dataset into training and evaluation subsets\n",
        "\n",
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['evaluate'] = Subset(dataset, val_idx)\n",
        "    return datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X80eZlVMLo5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X80eZlVMLo5a",
        "outputId": "6dd6130d-a327-4797-df40-15ecaf1ada1c"
      },
      "outputs": [],
      "source": [
        "# Let's see the size of each training set\n",
        "datasets = train_val_dataset(Sample_Dataset)\n",
        "print(f\"Training Dataset: {len(datasets['train'])} data points.\")\n",
        "print(f\"Evaluation Dataset: {len(datasets['evaluate'])} data points.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69cb4ae5-70a9-4c20-8a4b-f88009821bcc",
      "metadata": {
        "id": "69cb4ae5-70a9-4c20-8a4b-f88009821bcc"
      },
      "outputs": [],
      "source": [
        "# Creating the Dataloaders for both the 'train' and the 'eval' datasets\n",
        "# Here the datasets ('train' and 'evaluate') are input into DataLoaders\n",
        "# DataLoaders deliver the data to the training algorithm when requested.\n",
        "# They deliver the data in 'minibatches' , and reshuffle the data for each epoch\n",
        "train_dataloader = DataLoader(datasets['train'], batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(datasets['evaluate'], batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yhCeLAcySSY6",
      "metadata": {
        "id": "yhCeLAcySSY6"
      },
      "outputs": [],
      "source": [
        "# Checking GPU Status\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "images, ann, xy = next(iter(train_dataloader))\n",
        "# send data to device\n",
        "images = images.to(device)\n",
        "xy = xy.to(device)\n",
        "\n",
        "# GPU Test\n",
        "print(f\"Images on GPU: {images.is_cuda}\")\n",
        "print(f\"Labels on GPU: {xy.is_cuda}\")\n",
        "\n",
        "print(f\"Index for the GPU device: {torch.cuda.current_device()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ra1dADI94e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ra1dADI94e",
        "outputId": "2a037d60-c696-46f7-8467-1b5ca1fc03ba"
      },
      "outputs": [],
      "source": [
        "# Plot Image, Label, and File Name\n",
        "\n",
        "# Get an image, associated annotations, and training labels from the training dataloader\n",
        "train_image, ann, train_labels = next(iter(train_dataloader))\n",
        "\n",
        "# Converting the image from tensor to numpy array\n",
        "img_out = train_image.numpy()[0]\n",
        "img_out = np.moveaxis(img_out, 0, -1)\n",
        "\n",
        "# Onverting the label to xy\n",
        "x = train_labels[1].numpy()[0] # Converting from tensor\n",
        "x = int(224 * (x / 2.0 + 0.5)) # mapping the [-1,1] range to [0,224] range\n",
        "print(f\"X Label: {x}\")\n",
        "\n",
        "fig = plt.figure(figsize= (7, 7))\n",
        "ax = fig.add_axes()\n",
        "circ = Circle((x,112),15)\n",
        "\n",
        "\n",
        "ax.add_patch(circ)\n",
        "\n",
        "fig.imshow(img_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N_xEIkOPzAHn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "N_xEIkOPzAHn",
        "outputId": "1b9b2ebc-9c08-4fae-c875-217a207f1496"
      },
      "outputs": [],
      "source": [
        "# Plot a grid of images with their labels\n",
        "fig = plt.figure(figsize= (14, 14))\n",
        "for i in range (0,12):\n",
        "  # Create a grid for our images\n",
        "  ax = fig.add_subplot(4, 4, i+1)\n",
        " \n",
        "  # Use the train_data loader to get images and labels from the \n",
        "  # training dataset\n",
        "  train_image, ann, train_labels = next(iter(train_dataloader))\n",
        "  train_image = train_image.numpy()[0]\n",
        "  train_image = np.moveaxis(train_image, 0, -1)\n",
        "  x = int(train_labels[i].numpy()[0])\n",
        "  x = int(224 * (x / 2.0 + 0.5))\n",
        "\n",
        "  # From the annotations we get the solution and plot it\n",
        "  circ = Circle((x,112),15)\n",
        "  ax.add_patch(circ)\n",
        "  ax.text(10,20,ann['image_path'][0][26:30])\n",
        "  ax.text(10,40, str(x))\n",
        "  ax.imshow(train_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_2aTq-OIXwgo",
      "metadata": {
        "id": "_2aTq-OIXwgo"
      },
      "outputs": [],
      "source": [
        "# Model Setup\n",
        "# RESNET 18\n",
        "output_dim = 2\n",
        "\n",
        "# Loading a pretrained ResNet18 model.\n",
        "# Note: we're going to retrain all layers of this model\n",
        "# This decision was made based on the amount of data available and the complexity of the task\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# RESNET 34\n",
        "#model = torchvision.models.resnet34(pretrained=True)\n",
        "\n",
        "\n",
        "# If you wanted to train fewer of the layers (freeze some layers)\n",
        "#Freeze all of the weights in ResNet18\n",
        "#for param in model.parameters():\n",
        "#  param.requires_grad = False\n",
        "\n",
        "# Adding a fully connected layer to the top/head of the model\n",
        "model.fc = torch.nn.Linear(512, output_dim)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bYXsdSOYS4M",
      "metadata": {
        "id": "0bYXsdSOYS4M"
      },
      "outputs": [],
      "source": [
        "# Training Setup\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UCiWhXxSZdq_",
      "metadata": {
        "id": "UCiWhXxSZdq_"
      },
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "model_file_name = 'Models/my_new_model.pth'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def training_and_evaluation(epochs):\n",
        "  # Training Timing\n",
        "  start_time = datetime.now()\n",
        "\n",
        "  # Writing training details to training log\n",
        "  f = open(\"training_log.txt\", \"a\")\n",
        "  f.write(\"\\n\")\n",
        "  dt_string = start_time.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
        "  f.write(f\"Training Report: {dt_string} \\n\")\n",
        "  f.write(f\"Selected Dataset: {dataset_folder_name}, Number Data Points: {num_files}\\n\")\n",
        "  f.write(f\"Model: {model.__class__.__name__}{18}, Epochs: {epochs}, Batch Size: {BATCH_SIZE}\\n\")\n",
        "  # Remaining details will be written at the end of the training\n",
        "\n",
        "  ############# Initiating Training Process ##############\n",
        "  # First set model to train mode\n",
        "  model.train()\n",
        "\n",
        "  print(\"Starting training process ...\")\n",
        "  # Start training process dependent on number of epochs\n",
        "  while epochs > 0:\n",
        "    print(\"######### Epoch: \" + str(epochs) + \" #########\")\n",
        "    # Index\n",
        "    i = 0\n",
        "    sum_loss = 0.0\n",
        "    error_count = 0.0\n",
        "\n",
        "    # Training Loop\n",
        "    # Process each batch of data points in the train loader\n",
        "    for images, category_idx, xy in iter(train_dataloader):\n",
        "      # send data to device\n",
        "      images = images.to(device)\n",
        "      xy = xy.to(device)\n",
        "\n",
        "      # zero gradients of parameters\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # execute model to get outputs\n",
        "      outputs = model(images)\n",
        "\n",
        "      # compute MSE loss over x, y coordinates for associated categories\n",
        "      loss = 0.0\n",
        "      loss += torch.mean((outputs - xy)**2)\n",
        "      #for batch_idx, cat_idx in enumerate(list(category_idx.flatten())):\n",
        "      #    loss += torch.mean((outputs[batch_idx][2 * cat_idx:2 * cat_idx+2] - xy[batch_idx])**2)\n",
        "      #loss /= len(category_idx)\n",
        "\n",
        "      # run backpropogation to accumulate gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # step optimizer to adjust parameters\n",
        "      optimizer.step()\n",
        "\n",
        "      # increment progress\n",
        "      # NO TRAINING ACCURACY: no correct answer for regression, only loss\n",
        "      #count = len(category_idx.flatten())\n",
        "      #i += count\n",
        "      i += len(xy)\n",
        "      sum_loss += float(loss)\n",
        "      #progress_widget.value = i / len(dataset)\n",
        "      #loss_widget.value = sum_loss / i\n",
        "\n",
        "\n",
        "      print(\"Loss: \" + str(sum_loss/i))\n",
        "\n",
        "    #sum_loss.append(totalLoss)\n",
        "    #print(f\"Training Accuracy: {testAccuracy / len(training)}\")\n",
        "\n",
        "\n",
        "    # Evaluation Loop\n",
        "    i = 0\n",
        "    evaluation_loss = 0.0\n",
        "    for images, category_idx, xy in test_dataloader:\n",
        "\n",
        "        # Put the model into evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # send data to device\n",
        "        images = images.to(device)\n",
        "        xy = xy.to(device)\n",
        "\n",
        "        # execute model to get outputs\n",
        "        outputs = model(images)\n",
        "\n",
        "        # compute MSE loss over x, y coordinates for associated categories\n",
        "        loss = 0.0\n",
        "        loss += torch.mean((outputs - xy)**2)\n",
        "        i += len(xy)\n",
        "        evaluation_loss += float(loss)\n",
        "    print(f\"Validation Accuracy: {evaluation_loss / i}\")\n",
        "    #Save our model for each epoch\n",
        "    #torch.save(model.state_dict(), file)\n",
        "\n",
        "    # End of the current epoch\n",
        "    epochs = epochs -1\n",
        "  end_time = datetime.now()\n",
        "\n",
        "  # get the execution time\n",
        "  elapsed_time = end_time - start_time\n",
        "  training_duration_time_formatted = str(elapsed_time)\n",
        "  print('Execution time:', training_duration_time_formatted)\n",
        "\n",
        "\n",
        "  f.write(f\"Final model evaluation loss: {evaluation_loss/i}\\n\")\n",
        "  f.write(f\"Total training & evaluation time: {training_duration_time_formatted}\\n\")\n",
        "  f.write(f\"Model File Name: {model_file_name}\")\n",
        "  f.write(\"\\n\")\n",
        "  f.close()\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "model = training_and_evaluation(epochs)\n",
        "torch.save(model.state_dict(), model_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YWqxmN0ok9Sv",
      "metadata": {
        "id": "YWqxmN0ok9Sv"
      },
      "outputs": [],
      "source": [
        "# Model output test\n",
        "\n",
        "# Iterate through the DataLoader\n",
        "train_images, ann, train_labels = next(iter(train_dataloader))\n",
        "\n",
        "# send data to device\n",
        "images = train_images.to(device)\n",
        "xy = train_labels.to(device)\n",
        "outputs = model(images)\n",
        "\n",
        "# Check"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
